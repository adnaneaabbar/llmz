{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ca295b-a4b5-42cd-b6ea-9d1cd756f78a",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4ec7ea-24bd-4f94-bcee-b7e78625de88",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "edcc6409-d049-47ed-a8a1-101b89312a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ollama version is 0.1.47\n"
     ]
    }
   ],
   "source": [
    "!docker exec ollama ollama -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7e173-50ee-4764-8063-5fcc99e8e605",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be0be703-2102-4180-bd41-102966f48533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling c1864a5eb193... 100% ▕████████████████▏ 1.7 GB                         \n",
      "pulling 097a36493f71... 100% ▕████████████████▏ 8.4 KB                         \n",
      "pulling 109037bec39c... 100% ▕████████████████▏  136 B                         \n",
      "pulling 22a838ceb7fb... 100% ▕████████████████▏   84 B                         \n",
      "pulling 887433b89a90... 100% ▕████████████████▏  483 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "removing any unused layers \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!docker exec ollama ollama pull gemma:2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20a85796-af3e-411d-9027-25664327f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec ollama cat root/.ollama/models/manifests/registry.ollama.ai/library/gemma/2b >> manifest.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b38447f7-680b-4128-b511-7d80c41255ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"schemaVersion\": 2,\n",
      "    \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\",\n",
      "    \"config\": {\n",
      "        \"mediaType\": \"application/vnd.docker.container.image.v1+json\",\n",
      "        \"digest\": \"sha256:887433b89a901c156f7e6944442f3c9e57f3c55d6ed52042cbb7303aea994290\",\n",
      "        \"size\": 483\n",
      "    },\n",
      "    \"layers\": [\n",
      "        {\n",
      "            \"mediaType\": \"application/vnd.ollama.image.model\",\n",
      "            \"digest\": \"sha256:c1864a5eb19305c40519da12cc543519e48a0697ecd30e15d5ac228644957d12\",\n",
      "            \"size\": 1678447520\n",
      "        },\n",
      "        {\n",
      "            \"mediaType\": \"application/vnd.ollama.image.license\",\n",
      "            \"digest\": \"sha256:097a36493f718248845233af1d3fefe7a303f864fae13bc31a3a9704229378ca\",\n",
      "            \"size\": 8433\n",
      "        },\n",
      "        {\n",
      "            \"mediaType\": \"application/vnd.ollama.image.template\",\n",
      "            \"digest\": \"sha256:109037bec39c0becc8221222ae23557559bc594290945a2c4221ab4f303b8871\",\n",
      "            \"size\": 136\n",
      "        },\n",
      "        {\n",
      "            \"mediaType\": \"application/vnd.ollama.image.params\",\n",
      "            \"digest\": \"sha256:22a838ceb7fb22755a3b0ae9b4eadde629d19be1f651f73efb8c6b4e2cd0eea0\",\n",
      "            \"size\": 84\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('manifest.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "formatted_json = json.dumps(data, indent=4)\n",
    "print(formatted_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608f2da4-8268-499c-9004-250b898d5c68",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef8e9cdc-dfd4-4e54-a332-4b9bde4e6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5472698d-3322-45d2-b126-ba1d29801782",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"10 * 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3d80e3e2-7e56-4359-a0c2-89cd8565523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_query(query):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gemma:2b',\n",
    "        messages=[{\"role\": \"user\", \"content\": query}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6883e5ef-2890-4061-85e7-00b718647438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure. I can assist you with your request.\\n\\n**10 * 10**\\n\\n**Step 1: Perform the multiplication operation.**\\n\\n10 * 10 = 100\\n\\n**Therefore, 10 * 10 = 100.**'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_query(query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b70efb64-8a8d-4201-8f94-6ee107efc54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure. I can assist you with your request.\n",
      "\n",
      "**10 * 10**\n",
      "\n",
      "**Step 1: Perform the multiplication operation.**\n",
      "\n",
      "10 * 10 = 100\n",
      "\n",
      "**Therefore, 10 * 10 = 100.**\n"
     ]
    }
   ],
   "source": [
    "print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3c6392-4ad7-4a89-8dd7-dfeab3c1be22",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "38feb630-1149-47ac-802a-a20e098ec0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ollama_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff85d749-5f3e-4972-b722-4f59cdcd2220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db922ab91e65f57ae8ce3259193a4f867017ef01bf43ff807f4292b0be631def\n",
      "docker: Error response from daemon: driver failed programming external connectivity on endpoint ollama (f00bb8793c97eeb52ebf86332ae8b6021ce14b2bdc5a75d92212a48039825207): Error starting userland proxy: listen tcp4 0.0.0.0:11434: bind: address already in use.\n"
     ]
    }
   ],
   "source": [
    "!docker run -d \\\n",
    "    --rm \\\n",
    "    -v ./ollama_files:/root/.ollama \\\n",
    "    -p 11434:11434 \\\n",
    "    --name ollama \\\n",
    "    ollama/ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dfe135-c6a0-4e9b-a77e-e766c5495437",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker exec -it ollama ollama pull gemma:2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a92fcc74-ff01-433a-b823-9b88d08df899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,6G\tollama_files/models/blobs\n",
      "8,0K\tollama_files/models/manifests/registry.ollama.ai/library/gemma\n",
      "12K\tollama_files/models/manifests/registry.ollama.ai/library\n",
      "16K\tollama_files/models/manifests/registry.ollama.ai\n",
      "20K\tollama_files/models/manifests\n",
      "1,6G\tollama_files/models\n"
     ]
    }
   ],
   "source": [
    "!du -h ollama_files/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b4f59f-c8cb-4bd4-b892-fbe9ef69b267",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03e040e-3b5c-4b98-a3ec-ee71a9b26020",
   "metadata": {},
   "source": [
    "```Dockerfile\n",
    "FROM ollama/ollama\n",
    "\n",
    "COPY ./ollama_files /root/.ollama\n",
    "\n",
    "EXPOSE 11434\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1cecad-4846-407c-916f-52b751702e03",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba55883e-45d9-4b8e-a111-3624665993ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (7/7) FINISHED                                 docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile                       0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 104B                                       0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load metadata for docker.io/ollama/ollama:latest            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load .dockerignore                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 2B                                            0.0s\n",
      "\u001b[0m\u001b[34m => [internal] load build context                                          0.0s\n",
      "\u001b[0m\u001b[34m => => transferring context: 1.16kB                                        0.0s\n",
      "\u001b[0m\u001b[34m => [1/2] FROM docker.io/ollama/ollama:latest                              0.0s\n",
      "\u001b[0m\u001b[34m => CACHED [2/2] COPY ./ollama_files /root/.ollama                         0.0s\n",
      "\u001b[0m\u001b[34m => exporting to image                                                     0.0s\n",
      "\u001b[0m\u001b[34m => => exporting layers                                                    0.0s\n",
      "\u001b[0m\u001b[34m => => writing image sha256:242a020e43597b00673348e32a651e389bbf8dfd5474f  0.0s\n",
      "\u001b[0m\u001b[34m => => naming to docker.io/library/ollama-gemma2b                          0.0s\n",
      "\u001b[0m\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!docker build -t ollama-gemma2b ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6d7afc9-d071-4253-9ee9-5280fb4a1f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28b805653b63fe2f96bdb33c855cdcb004226330ce8b22e1a93257aaf6d303a8\n"
     ]
    }
   ],
   "source": [
    "!docker run -d --rm -p 11434:11434 ollama-gemma2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "960ed673-2b78-45f1-8495-760e6280e02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url='http://localhost:11434/v1/',\n",
    "    api_key='ollama',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a78efe3e-6ebf-4614-bd77-137229843a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What's the formula for energy?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9d72c0a-6cd4-4715-8a52-a73ef74daa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='gemma:2b',\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    temperature=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deae8dad-ded4-406a-91df-a4fd89ba7aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a488ff7-b840-461e-99ac-56f928102aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's the formula for energy:\n",
      "\n",
      "**E = K + U**\n",
      "\n",
      "Where:\n",
      "\n",
      "* **E** is the energy in joules (J)\n",
      "* **K** is the kinetic energy in joules (J)\n",
      "* **U** is the potential energy in joules (J)\n",
      "\n",
      "**Kinetic energy (K)** is the energy an object possesses when it moves or is in motion. It is calculated as half the product of an object's mass (m) and its velocity (v) squared:\n",
      "\n",
      "**K = 1/2mv^2**\n",
      "\n",
      "**Potential energy (U)** is the energy an object possesses due to its position or configuration. It is calculated as the product of an object's mass, gravitational constant (g), and height or position above a reference point.\n",
      "\n",
      "**U = mgh**\n",
      "\n",
      "Where:\n",
      "\n",
      "* **m** is the mass in kilograms (kg)\n",
      "* **g** is the gravitational constant (9.8 m/s^2)\n",
      "* **h** is the height or position in meters (m)\n",
      "\n",
      "The formula shows that energy can be expressed as the sum of kinetic and potential energy. The kinetic energy is a measure of the object's ability to do work, while the potential energy is a measure of the object's ability to do work against a force.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2dcace7-d557-454b-b769-13a8a8bff82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage.completion_tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
